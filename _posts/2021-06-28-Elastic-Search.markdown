---
layout: post	
title: "검색 속도 향상을 위한 Elastic Search 도입"
date: 2021-06-28
categories:
  - Back-End-Study
description:
image: https://res.cloudinary.com/danhdvla9/image/upload/v1626075640/Thumbnails/elasticsearch_r9lm84.png
image-sm: https://res.cloudinary.com/danhdvla9/image/upload/v1626075640/Thumbnails/elasticsearch_r9lm84.png
image-me: https://res.cloudinary.com/danhdvla9/image/upload/v1614694302/Blacksmith_vqd5bz.png
---

<br>
<br>

## MQ까지 도입했는데... 특정 상황에서는 아직 서버가 죽네 ㅠㅠ  

<br>
<br>

지금까지 포스팅을 해가며 대용량 트래픽 프로젝트에 MQ까지 도입했다. **"이제 요청을 큐에 저장하며 순차적으로 처리하기 때문에 쓰레드가 꽉 차지만 않으면 문제없겠다!"** 라고 생각하였다. 하지만 생각이 끝나고 몇 초 뒤... 쓰레드 자원이 모두 소진되어 팡팡 터지고 있는 서버가 상상되어 다시 키보드를 잡는다. 우선 문제의 저 쓰레드가 꽉 차는 상황에는 무엇이 있을지 위험분석을 해보도록 하자.

<br>
<br>

#### 많은 양의 데이터를 응답으로 보내는 경우

<br>
<br>

지금까지 따로 명시하지는 않았지만 데이터로 불특정다수의 애니메이션 리뷰 댓글들을 크롤링하여 사용하고 있고 크기는 대략 50000개 정도이다. '애니'라는 단어로 게시글을 찾을 경우 많은 양의 데이터를 응답으로 보내게 되면서 latency가 길어지는 결과를 보였다. 실제로 쓰레드 자원이 모두 소진되어 요청이 거절되고 있는 것은 아니지만 더 많은 데이터를 가지고 있을 경우 그렇게 될 가능성은 짙다.  
**즉, 여기서 알 수 있는 것은 응답으로 보내는 데이터 양이 많아지면 많아질수록 쓰레드가 요청을 처리하는 시간이 길어지고 (응답까지 완료되어야 가용 가능한 쓰레드가 되기 때문에) 요청이 밀리면서 거절된다는 것을 예상할 수 있겠다.**  
그럼 데이터 양이 많아질수록 왜 시간이 길어지는 걸까? 내가 생각한 큰 이유는 두 가지이다.  
  
1. 네트워크가 느려서 데이터의 전송이 느리다.
2. 요청에 맞는 데이터 색인에 시간이 오래걸린다.  
  
전자의 경우는 네트워크 환경과 더 밀접하기 때문에 무료 평가판을 사용하고있는 현재 상황에서는 최선이라 생각한다. 클라우드 쪽에서 네트워크와 관련된 설정으로는 MQ를 도입하면서 리전의 거리에 따른 latency 증가를 확인하고 해결해놓은 상태이다. 이것 이외의 문제점이 발생한다면 그것은 구글 클라우드 내부에서의 문제이거나 클라이언트의 네트워크 환경일 것이라 생각한다.  
그래서 더욱 중심을 두고 봐야할 부분은 후자이다. 데이터가 많을수록 색인에 시간이 오래걸릴것은 당연하다. 전자보다는 후자를 개선하는 방향으로 진행하기로 결정하며 이를 조금 더 완화하기위해 Elastic Search라는 툴을 도입하기로 했다. Elastic Search는 어떤 도구일까?

<br>
<br>

#### Elastic Search란? 

<br>
<br>

Elastic Search(이하 ES)가 제공하는 기능 중 특징적으로 3가지 기능이 있다.  
  
  - Inverted Index (역색인)
  - Shard (샤드)
  - Replica (레플리카)  
  
**역 색인**을 설명하기위해 먼저 보통의 RDBS 테이블과 비교할 필요가 있다. 보통 RDBS의 테이블은 키와 값으로 이루어져있다. 하지만 ES의 역 색인은 RDBS 테이블안의 값 내용 중 단어를 뽑아내어 키로 두고, 값에는 RDBS 테이블에서 값이 위치하는 키의 값을 넣는다.  

---
EX)  
RDBS Table  
```
key         value
0           스타벅스 아메리카노
1           할리스 아메리카노
2           스타벅스 라떼 
```  
Inverted Index Table  
```
key         value
"스타벅스"    0,2
"할리스"      1
"아메리카노"   0,1
"라떼"       2
```  
---

이렇게 정리된 역 색인 테이블에서 만약 "스타벅스"를 검색한다면 0번, 2번 데이터만 가져오면 되므로 따로 검색 알고리즘을 타고 데이터를 찾으러다닐 필요가 없어진다.  
**한글 형태소는 정확하게 구분이 안되므로 ES에 nori(노리)또는 arirang(아리랑)같은 분석기를 적용해야한다!**
  

**샤드**는 간단히말해 저장된 데이터를 원하는만큼 쪼개어 여러 곳에 저장해놓는 것이다. ES 클러스터를 여러개 구동하게하여 이 쪼개진 문서들을 분산해서 검색하게 한다면 훨씬 빠르게 데이터를 검색할 수 있을 것이다. 하지만 무조건 샤드를 많이 만든다고 성능이 좋아지는 것은 아니니 최소한으로 쪼개고 최대한으로 효율을 낼 수 있는 선을 찾아서 샤드를 나누어놓자.  
  

**레플리카**는 쪼개진 샤드를 몇 개 복제할지 정하는 것이다. 레플리카를 사용할 때의 이점은 예상치못하게 클러스터가 다운된 경우에도 서비스가 원활이 이루어질 수 있다. 레플리카를 만들면 키워드당 매칭되는 문서에 따라 검색 효율이 낮아지기도하지만 안정성이라는 큰 장점을 위해서는 조금 희생할 가치가 있다고 생각한다.  
  

<br>
<br>

#### Elastic Search의 단점

<br>
<br>

ES의 단점으로는 크게 세가지가 있다.  
  
- 실시간 처리 불가
- 트랜잭션과 롤백을 제공하지 않음
- 데이터를 실제로 업데이트하지 않음 

이 중 세번째 항목에 관해서 부가 설명을 하자면, 업데이트 기능은 있지만 기존의 데이터를 지우고 새로만드는 방식으로 업데이트한다. 따라서 실시간으로 입력되는 데이터들을 빠르게 색인해야하는 경우에는 ES가 크게 적합하다고 말할 수는 없다.  

<br>
<br>

#### Elastic Search를 도입하고... 

<br>
<br>

클러스터는 4개, 샤드는 8개로 구성하여 진행한 결과, '애니'라는 키워드를 검색했을 때 기존 DB만을 이용했을 때보다 약 2초 정도 감소하었다. 뿐만 아니라 '애니'보다 latency가 짧았던 '명작', '진짜' 키워드를 검색했을때도 약 1초정도 감소한 결과를 보여주었다.  
여기서 추가로 레플리카 수를 1로 해서 진행한 결과 '애니' 키워드는 기존 DB만을 이용했을 때보다 조금 더 늘었지만 나머지는 비슷하게 유지되었다.  
  
  *결론을 내리자면...*  
  
  - 키워드와 매칭되는 문서가 많을수록 DB가 더 효율적일 수 있다.
  - 클러스터와 샤드의 개수를 늘리면 늘릴수록 더욱 색인이 빨라진다.
  - 레플리카는 안정성을 늘려주지만 매칭이 많은 키워드의 검색 효율은 낮춘다.

**이 결론은 내가 테스트해본 환경에서의 결론이다.** 데이터의 갯수와 내용에 따라 언제든지 결과가 달라질 수 있으므로 각자의 환경에서 테스트를 거쳐 도입을 결정해야한다!!  

도입을 하고 느낀점은  
*"확실히 검색 속도를 낮출 수 있는 좋은 방법이다! 하지만 클러스터가 꽤 많아야되겠는데...?"*  
이다. ES의 겉만 핥아서 이보다 더 큰 효율을 낼 수 있는 ES의 기능에는 무엇이 있을지 아직 모르지만, 지금 상태로 ES와 클라우드를 합쳐서 사용하려면 비용쪽으로 많이 고려해봐야 할 것 같다는 소감이다. 또한 클라우드에서 클러스터로 사용하기위해 인스턴스를 띄워서 도커를 설치해 사용했는데, 단일 스택 클러스터만을 위한 제품을 사용한다면 비용이 어떻게 변할지 탐구해 봐야한다. 하지만 이번 프로젝트에서 비용적인 면은 무료 크레딧으로 해결하고 있기 때문에 당장 고려할 점이 아니므로 더 다루지 않기로 했다. 

<br>
<br>

이것으로 ES 도입 포스팅을 마친다.