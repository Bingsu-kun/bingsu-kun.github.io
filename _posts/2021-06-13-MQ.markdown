---
layout: post	
title: "더욱 원활한 DB 접근을 위해 MQ와 캐싱을 도입하자"
date: 2021-06-13
categories:
  - Back-End-Study
description:
image: https://res.cloudinary.com/danhdvla9/image/upload/v1617008667/Thumbnails/jenkins_vhzpmh.png
image-sm: https://res.cloudinary.com/danhdvla9/image/upload/v1617008667/Thumbnails/jenkins_vhzpmh.png
image-me: https://res.cloudinary.com/danhdvla9/image/upload/v1614694302/Blacksmith_vqd5bz.png
---

<br>
<br>

## Message Queue를 사용하자!

<br>
<br>

Message Queue (이하 MQ)는 웹 서버와 DB사이에 위치하여 서버에서 DB에 접근하는 요청을 받아 Queue에 임시로 저장해주고 차례로 처리할 수 있도록 도와주는 툴이다. 앞서 nginx를 활용한 Load Balancing을 통해 클라이언트가 서버에 접근하는 것 까지는 개선할 수 있었다. 하지만 웹 서버를 여러개 구동한다고 해도 결국에 데이터를 구하기위해 DB에 접근하게 되는데 이때 DB의 성능은 한계가 있고, DB개수를 늘린다고 해도 너무 많아지면 동기화때문에 데이터 무결성 유지가 힘들어진다. 그래서 DB에 향하는 요청을 중계해주기위해 등장한 것이 MQ이다.  
좀 더 자세히 들어가보자. 만약 운영 중인 웹 서버가 3대이고, 요청 타임 아웃시간은 3초, DB가 한 개의 요청을 처리하는데 3초가 걸린다고 가정한다면, ~~이 DB는 갖다 버려야한다~~ 세 서버에서 동시에 요청이 들어왔을 때 한 가지 요청밖에 응답하지 못한다. 그래서 MQ는 이렇게 요청이 몰릴 때 요청들을 Queue로 받아들인 후 클라이언트에게는 Queue 대기 순번을 응답해주고, DB에게는 순차적으로 몰렸던 요청들을 처리한다. 따라서 불필요하게 많은 클라이언트의 요청을 받을 필요도 없어지고 네트워크 불량으로인한 타임 아웃 처리와 요청의 램프업으로 인해 응답이 늦어지는 상황의 처리를 따로 할 수 있게되어서 효율과 편리 두 가지를 모두 잡을 수 있다고 할 수 있다.  

<br>
<br>

#### RabbitMQ 사용하기

<br>
<br>

Message Queue 중에서도 다른 개발자사이에 이름이 많이 오가고 많이 사용되는 RabbitMQ를 사용해보기로 했다. MQ를 처음 배워보기 때문에 아티클이 많은 툴이 공부하기 편할 것 같아서 선택하게 되었다.  
우선 MQ를 사용할 땐 웹 서버에 Producer와 Consumer 라는 클래스를 별도로 만들어서 사용하게 된다. 웹 서버 소스코드에서 findById 같은 API 메서드를 제작하여 사용할 때 jpa나 jdbctemplate 인스턴스로 바로 접근하지않고 Producer 인스턴스를 만들어서 MQ로 요청이 가게끔 해준다. 다음 Consumer에 DB접근 인스턴스 메서드를 담아 리스너를 사용해서 Queue의 요청을 처리하게 하는 식이다. 추가적으로 DB는 PostgreSQL을 사용하였다.  
아래는 Producer와 Consumer의 예시 코드이다.  

```
public class Producer {

	@Autowired
	private RabbitTemplate rabbitTemplate

	public void sendTo(String message) {
		this.rabbitTemplate.convertAndSend("큐 이름을 넣어주세요",message);
	}
}
```  

```
public class Consumer {

	@Autowired
	ObjectMapper objectMapper;

	@Autowired
	PostRepository postRepository;

	@RabbitListener(Queues = "큐 이름을 넣어주세요") // 큐에 작업이 있을 경우 메세지로 받아옴
	public void handler(String message) throws JsonProcessingException {
		Post post = objectMapper.readValue(message, Post.class); //리스너를 통해 받아온 메세지를 post 클래스에 매핑.
		postRepository.save(post)
	}
}
```  

이렇게 Queue에 들어있는 요청을 처리하는 코드를 작성하였는데, 때에 따라서는 Queue가 있는 장비나 인스턴스가 문제를 일으키는 경우도 있어, 여러 Queue를 운영하기도 한다. 이 때 Queue는 동기화해서 사용한다.  
추가적으로 주의해야할 점은 RabbitMQ를 운영하는 인스턴스에서 외부 포트를 열어줄 때, RabbitMQ 모니터링 포트와 Queue로 요청하는 포트 이렇게 두 포트를 열어주어야 한다. 그렇게해야 모니터링 포트로 접속하여 새로운 큐를 만들어 줄 수 있을 뿐더러 큐 관리까지 가능하다. 모니터링 페이지에 접속한 후에는 유저 로그인 창이 뜨는데 첫 접속은 아이디 guest, 비밀번호 guest로 해서 접속가능하고 들어가서 아이디를 새로 만들어주는 것을 추천한다.  

<br>
<br>

#### 캐싱을 해보자 !

<br>
<br>

우리가 흔히 접속하는 사이트의 첫 페이지에는 꽤나 많은 양의 정보를 담고있는 경우가 많다. 예를들어 네이버의 경우 첫 페이지에 검색 창과 더불어 실시간으로 뉴스나 기사들을 볼 수 있는 링크가 즐비하다. 이와 관련된 내용들은 전부 DB에서 가져오는 것일테고, 모든 사용자가 이 페이지를 자주 요청하게 되면서 DB에 요청하는 데이터의 양과 횟수가 상당할 것이다. 당연히 DB입장에서는 부담이 될텐데 이를 웹 서버에서 미리가져와서 준비해놓고 있는다면? DB에 접근하지 않고도 페이지의 정보를 응답할 수 있기 때문에 DB도 훨씬 부담이 적어질테고 사용자 입장에서도 페이지를 띄우는 시간이 짧아져 편리할 것이다. 우리는 이를 **캐싱**이라 부르고 있는데 DB와 MQ에 가해지는 부하를 줄이기 위해 간단하게 만들어보았다.  

Scheduler를 통해 주기적으로 DB에서 첫 페이지와 관련된 데이터를 받아오고 유저가 그 데이터를 요청할 경우 캐싱한 데이터를 바로 보낸다. 이는 꼭 첫 페이지가 아니라도 자주 접근되어지는 데이터가 있다면 캐싱 가능하다. 간단하게 구현한 것이기 때문에 웹 서버 소스코드에서 구현하였지만, 일반적으로는 웹 서버 소스코드에 직접 구현하지 않고 **Redis**같은 캐시 서버 툴을 이용해서 캐싱한 데이터를 저장해 두었다가 필요할 때 접근해서 보낸다.  
아래는 간단하게 구현한 코드이다.  

```
public class PostCacheService {

	@Autowired
	PostRepository postRepository;

	private Page<Post> firstPage;

	@Scheduled(cron = [크론식]) //크론식에 따라 작성해주면 주기적으로 데이터를 캐싱해옴.
	public void updateFirstPage() {
		firstPage = postRepository.findAll(
			PageRequest.of(0, 20, Sort.by("id").aescending()) // 첫페이지에 필요한 데이터를 미리 캐싱. 예시에서는 첫페이지에서 모든 데이터를 20개로 쪼갠 page 중 0번 page를 오름차순으로 불러온다. 
		);
	}

	public Page<Post> getFirstPage() {
		retrun this.firstPage;
	}

}
```  

이 때 주의해야할 점이 **반드시 main함수가 있는 클래스에 @EnableScheduling 어노테이션**을 적어줘야 정상 작동한다. 여기까지 캐싱을 준비하고 스트레스 테스트를 해보면 확실히 응답률이 좋아지긴 했으나 한가지 더 해결해야할 숙제가 남아있었다.  

<br>
<br>

#### 클라우드를 이용한다면 Region에 주목하자

<br>
<br>

나는 GCP를 이용해서 이 프로젝트를 진행 중이다. 인스턴스가 적을 때에는 인스턴스간 거리와 그에따른 지연률을 크게 고려하지 않았으나, 점점 인스턴스가 많아지고 하나의 요청을 처리할 때 인스턴스 사이를 오가는 횟수가 많아지면서 인스턴스간 거리를 주목하게 되었다. 다음은 수정 전 인스턴스들의 리전이다.  

<br> 

대한민국 서울 - 웹 서버 워커노드 3대  
대만 - nginx  
일본 도쿄 - rabbitMQ, PostgreSQL DB  

<br>

이 경우 요청의 플로우는 서울(클라이언트) -> 대만(nginx) -> 서울(worker node) -> 도쿄(rabbitMQ) -> 도쿄(PostgreSQL) -> 도쿄(rabbitMQ) -> 서울(worker node) -> 대만(nginx) -> 서울(클라이언트) 이다. 아시아 권역안에서만 움직이긴해도 시간으로 따지면 지연시간이 꽤 나온다. 이는 Postman에서 요청을 넣으면 확인해볼 수 있다. 나는 0.3s 정도의 지연시간이 나왔다. 이 시간을 줄이면 줄일수록 요청을 처리할 수 있는 빈 쓰레드가 빨리 생겨 많은 요청을 처리할 수 있게된다. **그러므로 nginx와 worker node들, rabbitMQ는 같은 리전에 두는것이 좋다.** 따라서 이를 변경한 결과,  

<br> 

대한민국 서울 - (nginx + 웹 서버 워커노드) 1대, 웹 서버 워커노드 1대, rabbitMQ 1대  
~~대만 - nginx~~  
일본 도쿄 - PostgreSQL DB  

<br>

이렇게 구성이 변경되었다. 이렇게 다시 지연시간을 테스트한 결과 0.12s 정도로 줄어들었다. 클라우드를 사용하고 있는 경우 가장 빠르고 확실하게 성능을 올릴 수 있는 좋은 방법일 것 같다.  

<br>
<br>

#### 주의사항 

<br>
<br>

linux 서버로 nginx 구동 시 nofile limit 때문에 요청이 막히는 경우가 있다. (Too many open files 에러) 이 경우 `prlimit` 커맨드를 사용해서 한계를 늘려주어야 한다. 기본적으로 1000으로 되어 있는데 `/proc/sys/fs/file-max`를 cat 명령어로 확인해보면 대략 36만 까지 키울 수 있었다.(GCP medium 기준) 